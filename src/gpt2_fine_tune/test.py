import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from utils.cuda_data import Cuda_data

import config

class LLM:
    tokenizer = None
    model = None

    def __init__(self):
        self.cuda = Cuda_data()
        self.cuda.check()
        self.load_model()

    def load_model(self):
        print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        self.tokenizer = AutoTokenizer.from_pretrained(config.MODEL_PATH)
        self.model = AutoModelForCausalLM.from_pretrained(config.MODEL_PATH)

        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º self.cuda.device –∫–∞–∫ –æ–±—ä–µ–∫—Ç, –∞ –Ω–µ —Ñ—É–Ω–∫—Ü–∏—é
        self.model.to(self.cuda.device)
        self.model.eval()
        print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

    # =========================
    # –ì–ï–ù–ï–†–ê–¶–ò–Ø
    # =========================
    def generate_answer(self, prompt):
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.cuda.device)

        with torch.no_grad():
            output_ids = self.model.generate(
                **inputs,
                max_new_tokens=config.MAX_NEW_TOKENS,
                do_sample=True,
                temperature=0.7,
                top_p=0.8,
                repetition_penalty=1.1,
                eos_token_id=self.tokenizer.eos_token_id,
            )

        text = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)

        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ –ø—Ä–æ–º–ø—Ç–∞
        response = text[len(prompt):]

        # –£–¥–∞–ª—è–µ–º "user:" –∏ "assistant:" (–ª—é–±–æ–π —Ä–µ–≥–∏—Å—Ç—Ä)
        import re
        response = re.sub(r'(?i)(user:|assistant:)', '', response)

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ
        response = response.lstrip()

        # –£–¥–∞–ª—è–µ–º –∑–∞–ø—è—Ç—É—é, —Ç–∏—Ä–µ –∏–ª–∏ –¥–≤–æ–µ—Ç–æ—á–∏–µ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
        if response and response[0] in ',:-‚Äî':
            response = response[1:].lstrip()

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        response = response.strip()

        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
        while '\n\n' in response:
            response = response.replace('\n\n', '\n')

        # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø—É—Å—Ç–æ–π
        if not response:
            return "ü§î"

        return response
